# **Hotel-Booking-Cancellation-Forecast**

Pipeline End-to-End: IoT ‚Üí Data Lake ‚Üí Banco ‚Üí Modelagem ‚Üí MLflow ‚Üí Dashboard

Este projeto implementa um pipeline completo de **Engenharia de Dados, IoT e Machine Learning** para previs√£o de cancelamento de reservas de hotel.
O fluxo integra **ThingsBoard**, **FastAPI**, **MinIO**, **JupyterLab**, **MLflow**, al√©m da reprodu√ß√£o e expans√£o de um paper de refer√™ncia na √°rea.

O objetivo final √© criar uma solu√ß√£o **automatizada e reprodut√≠vel** que:

* coleta dados brutos via IoT,
* armazena e organiza em um data lake,
* processa e modela,
* versiona modelos,
* e exibe resultados em dashboards consolidados.

---

# üë• Equipe

Institui√ß√£o: Institui√ß√£o: CESAR School
Disciplina: Aprendizado de M√°quina - 2025.2

---

# **Arquitetura do Projeto**

Todo o pipeline roda via **Docker Compose**, orquestrando os seguintes servi√ßos:

### **1. Script Python ‚Üí ThingsBoard**

Envia dados simulados ou coletados de sensores para o ThingsBoard via MQTT/HTTP.

### **2. FastAPI ‚Üí Bucket**

API respons√°vel por consumir dados do ThingsBoard e armazen√°-los no bucket ‚Äúraw‚Äù do Data Lake.

### **3. Bucket ‚Üí MinIO (S3)**

O bucket armazena os dados brutos e processados.
A API ou scripts internos movem os dados para estruturas organizadas dentro do MinIO.

### **4. MinIO ‚Üí JupyterLab**

Notebooks utilizam o MinIO como fonte √∫nica de verdade para an√°lise explorat√≥ria, limpeza, prepara√ß√£o e modelagem.

### **5. Reprodu√ß√£o do Paper + Contribui√ß√µes**

A pipeline inclui um notebook dedicado √† reprodu√ß√£o do paper utilizado como refer√™ncia, seguido das melhorias e extens√µes propostas pelo time.

### **6. Versionamento de Modelos no MLflow**

Todos os experimentos e m√©tricas s√£o armazenados no MLflow Tracking Server.

### **7. Dashboard final**

Dashboard unificado consumindo:

* dados brutos do ThingsBoard (tempo real),
* previs√µes dos modelos registrados no MLflow.

---

# **Estrutura de Pastas**

```
/
‚îú‚îÄ‚îÄ docker-compose.yml       # Orquestra√ß√£o dos servi√ßos
‚îú‚îÄ‚îÄ scripts/                 # Scripts Python (envio ao ThingsBoard)
‚îÇ   ‚îî‚îÄ‚îÄ send_to_thingsboard.py
‚îú‚îÄ‚îÄ fastapi/                 # API respons√°vel por leitura do TB e escrita no bucket
‚îú‚îÄ‚îÄ buckets/                 # Estruturas de armazenamento no MinIO
‚îú‚îÄ‚îÄ jupyterlab/              # Configura√ß√µes do ambiente Jupyter
‚îú‚îÄ‚îÄ notebooks/               # Notebooks principais
‚îÇ   ‚îú‚îÄ‚îÄ eda_and_cleaning.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ model_training.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ paper_reproduction.ipynb
‚îÇ   ‚îî‚îÄ‚îÄ contributions.ipynb
‚îú‚îÄ‚îÄ mlflow/                  # Configura√ß√£o do servidor MLflow
‚îú‚îÄ‚îÄ dashboard/               # C√≥digo/configura√ß√£o do dashboard final
‚îî‚îÄ‚îÄ README.md                # Documenta√ß√£o do projeto
```

---

# **Como Executar o Projeto**

Abaixo est√° o guia completo para levantar a infraestrutura, coletar dados, treinar modelos e visualizar resultados.

---

## **Pr√©-requisitos**

* Docker Desktop instalado e rodando
* Git (opcional)
* Python 3.9+ (caso execute o script ThingsBoard fora do Docker)

---

# **Passo 1: Subir a Infraestrutura (Docker)**

Na raiz do projeto (onde est√° o `docker-compose.yml`):

```bash
docker-compose up -d --build
```

Verifique se todos os containers est√£o ativos:

```bash
docker ps
```

---

# **Passo 2: Enviar Dados para o ThingsBoard**

Execute o script localizado em `/scripts`:

```bash
python scripts/send_to_thingsboard.py
```

Certifique-se de ter configurado corretamente o **Device Token** do ThingsBoard.

Painel do ThingsBoard:
**[http://localhost:8080](http://localhost:8080)**

---

# **Passo 3: Ingest√£o de Dados (FastAPI ‚Üí Bucket)**

Acesse a documenta√ß√£o da API:

**[http://localhost:8000/docs](http://localhost:8000/docs)**

Use o endpoint respons√°vel por capturar as m√©tricas do ThingsBoard e envi√°-las para o bucket.

Exemplo:
`POST /ingest/thingsboard`

Se receber 200 OK ‚Üí dados armazenados com sucesso.

---

# **Passo 4: Armazenamento no MinIO**

Acesse o console:

**[http://localhost:9001](http://localhost:9001)**
Usu√°rio: `minioadmin`
Senha: `minioadmin`

Verifique se os dados brutos foram armazenados no bucket correspondente.

---

# **Passo 5: Notebooks (EDA, Modelagem e Paper)**

Acesse:

**[http://localhost:8888](http://localhost:8888)**

Abra os notebooks em `/notebooks`:

* `eda_and_cleaning.ipynb`
* `model_training.ipynb`
* `paper_reproduction.ipynb`
* `contributions.ipynb`

Executar tudo sequencialmente.

### Sa√≠das esperadas:

* Gr√°ficos e relat√≥rios em `/notebooks/outputs`
* Modelos registrados no MLflow
* Dados tratados enviados ao MinIO

---

# **Passo 6: Versionamento no MLflow**

Acesse:

**[http://localhost:5000](http://localhost:5000)**

Aqui voc√™ poder√°:

* acompanhar m√©tricas,
* comparar experimentos,
* armazenar modelos,
* gerar artefatos.

Experimento principal:
**Hotel_Booking_Cancellation_Forecast**

---

# **Passo 7: Dashboard Final**

O dashboard integra:

* dados brutos diretamente do ThingsBoard
* previs√µes dos modelos (via MLflow ou API)
* visualiza√ß√µes agregadas
* m√©tricas de cancelamento

Acesse a interface no container correspondente (ex.: Streamlit ou Grafana, dependendo da implementa√ß√£o).

---

# **Encerrando a Execu√ß√£o**

Para parar tudo:

```bash
docker-compose down
```
