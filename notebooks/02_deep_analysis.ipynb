{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5f6ace6",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebf4b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sqlalchemy import create_engine\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from sklearn.compose import ColumnTransformer\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.width', None)       \n",
    "pd.set_option('display.max_colwidth', None)   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa9e90d",
   "metadata": {},
   "source": [
    "## Cria√ß√£o do DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899ce649",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv() \n",
    "database_url = os.getenv(\"NEON_DATABASE_URL\")\n",
    "\n",
    "engine = create_engine(database_url)\n",
    "query = \"SELECT * FROM hotel_bookings\"\n",
    "\n",
    "df = pd.read_sql(query, engine)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ea25e7",
   "metadata": {},
   "source": [
    "### EDA\n",
    "\n",
    "\"Preprocessing includes lumping infrequent categories of the categorical predictor\n",
    "Country (originally with 126 levels or countries) into 11 levels (CN, DEU, ESP, FRA, GBR,\n",
    "IRL, NLD, PRT, USA, NULL and OTHER). The categorical predictor ReservedRoomType has\n",
    "11 levels, and the categorical predictor AssignedRoomType has 10 levels; the levels of these\n",
    "two predictors were lumped into a total of seven categories to increase the counts of\n",
    "infrequent levels.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72140387",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_hotel_categories(df):\n",
    "    \"\"\"\n",
    "    Replica o pr√©-processamento do paper:\n",
    "    - Country: 126 n√≠veis -> 11 n√≠veis (CN, DEU, ESP, FRA, GBR, IRL, NLD, PRT, USA, NULL, OTHER)\n",
    "    - ReservedRoomType (11 n√≠veis) e AssignedRoomType (10 n√≠veis) -> 7 categorias totais combinadas\n",
    "    \"\"\"\n",
    "    \n",
    "    df_processed = df.copy()\n",
    "    \n",
    "    priority_countries = ['CN', 'DEU', 'ESP', 'FRA', 'GBR', 'IRL', 'NLD', 'PRT', 'USA']\n",
    "    \n",
    "    def lump_country(country):\n",
    "        if pd.isna(country):\n",
    "            return 'NULL'\n",
    "        elif country in priority_countries:\n",
    "            return country\n",
    "        else:\n",
    "            return 'OTHER'\n",
    "    \n",
    "    df_processed['country'] = df_processed['country'].apply(lump_country)\n",
    "    \n",
    "    common_room_types = ['A', 'B', 'C', 'D', 'E', 'F']  # Baseado em datasets t√≠picos\n",
    "    \n",
    "    def lump_room_type(room):\n",
    "        if pd.isna(room):\n",
    "            return 'NULL'\n",
    "        elif room in common_room_types:\n",
    "            return room\n",
    "        else:\n",
    "            return 'OTHER'\n",
    "    \n",
    "    df_processed['reserved_room_type'] = df_processed['reserved_room_type'].apply(lump_room_type)\n",
    "    df_processed['assigned_room_type'] = df_processed['assigned_room_type'].apply(lump_room_type)\n",
    "    \n",
    "    return df_processed\n",
    "\n",
    "# APLICAR O PR√â-PROCESSAMENTO\n",
    "print(\"=== ANTES DO PR√â-PROCESSAMENTO ===\")\n",
    "print(\"Country n√≠veis √∫nicos:\", df['country'].nunique(), df['country'].unique()[:10])\n",
    "print(\"ReservedRoomType n√≠veis √∫nicos:\", df['reserved_room_type'].nunique())\n",
    "print(\"AssignedRoomType n√≠veis √∫nicos:\", df['assigned_room_type'].nunique())\n",
    "\n",
    "# Executar pr√©-processamento\n",
    "df = preprocess_hotel_categories(df)\n",
    "\n",
    "print(\"\\n=== DEPOIS DO PR√â-PROCESSAMENTO ===\")\n",
    "print(\"Country n√≠veis √∫nicos:\", df['country'].nunique(), sorted(df['country'].unique()))\n",
    "print(\"ReservedRoomType n√≠veis √∫nicos:\", df['reserved_room_type'].nunique(), sorted(df['reserved_room_type'].unique()))\n",
    "print(\"AssignedRoomType n√≠veis √∫nicos:\", df['assigned_room_type'].nunique(), sorted(df['assigned_room_type'].unique()))\n",
    "\n",
    "print(\"\\nDistribui√ß√£o Country (top 11):\")\n",
    "print(df['country'].value_counts().head(11))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9ead5a",
   "metadata": {},
   "source": [
    "### Pre Processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce239730",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['arrival_date_month'] = pd.Categorical(df['arrival_date_month'], \n",
    "                                          categories=[\"January\",\"February\",\"March\",\n",
    "                                                      \"April\",\"May\",\"June\",\"July\",\"August\",\n",
    "                                                      \"September\",\"October\",\"November\",\"December\"], \n",
    "                                          ordered=True)\n",
    "\n",
    "df['arrival_date_day_of_month'] = df['arrival_date_day_of_month'].astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fa1ee7",
   "metadata": {},
   "source": [
    "### Divis√£o de Treino e Teste\n",
    "    \"75% training set and a 25% test set to estimate the performance of the machine learning algorithms\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc986c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d9d5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['is_canceled'])\n",
    "y = df['is_canceled']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635f19bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968382f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "print(f\"X_test: {X_test.shape}, y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a452804d",
   "metadata": {},
   "source": [
    "### Normaliza√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68780cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. DIAGN√ìSTICO: Identificar qual coluna tem datas\n",
    "print(\"üîç COLUNAS COM MUITAS CATEGORIAS √öNICAS:\")\n",
    "for col in X_train.select_dtypes(include=['object']).columns:\n",
    "    unique_count = X_train[col].nunique()\n",
    "    if unique_count > 20:  # Suspeita de datas\n",
    "        print(f\"‚ùå {col}: {unique_count} n√≠veis √∫nicos\")\n",
    "        print(f\"   Amostra: {X_train[col].unique()[:5]}\")\n",
    "        print()\n",
    "\n",
    "# 2. TRATAR COLUNAS DE DATA PROBLEM√ÅTICAS\n",
    "def fix_date_columns(df):\n",
    "    df_fixed = df.copy()\n",
    "    \n",
    "    # Converter colunas suspeitas de data para num√©ricas ou remover\n",
    "    date_suspect_cols = []\n",
    "    for col in df_fixed.select_dtypes(include=['object']).columns:\n",
    "        if df_fixed[col].nunique() > 20:  # Muitas categorias = provavelmente data\n",
    "            try:\n",
    "                # Tentar converter para datetime e extrair features\n",
    "                pd.to_datetime(df_fixed[col], errors='coerce')\n",
    "                print(f\"üìÖ Convertendo {col} para num√©rico...\")\n",
    "                df_fixed[col] = pd.to_datetime(df_fixed[col], errors='coerce').dt.dayofyear\n",
    "            except:\n",
    "                # Se n√£o conseguir, remover a coluna\n",
    "                print(f\"üóëÔ∏è Removendo {col} (demasiadas categorias)\")\n",
    "                df_fixed = df_fixed.drop(columns=[col])\n",
    "    \n",
    "    return df_fixed\n",
    "\n",
    "# APLICAR TRATAMENTO\n",
    "X_train_fixed = fix_date_columns(X_train)\n",
    "X_test_fixed = fix_date_columns(X_test)\n",
    "\n",
    "# 3. AGORA O PREPROCESSADOR FUNCIONA\n",
    "continuous_cols = X_train_fixed.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_cols = X_train_fixed.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "print(f\"\\n‚úÖ Ap√≥s tratamento:\")\n",
    "print(\"Cont√≠nuas:\", continuous_cols)\n",
    "print(\"Categ√≥ricas:\", categorical_cols)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', MinMaxScaler(), continuous_cols),\n",
    "        ('cat', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore'), categorical_cols)\n",
    "    ])\n",
    "\n",
    "# FIT E TRANSFORM\n",
    "X_train_processed = preprocessor.fit_transform(X_train_fixed)\n",
    "X_test_processed = preprocessor.transform(X_test_fixed)\n",
    "\n",
    "print(f\"\\n‚úÖ X_train processado: {X_train_processed.shape}\")\n",
    "print(f\"‚úÖ X_test processado: {X_test_processed.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04060780",
   "metadata": {},
   "source": [
    "### Treinamento dos Modelos e Otimiza√ß√£o dos hiperpar√¢mtros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde57e96",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c77000",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "numeric_cols = X_train.select_dtypes(include=[np.number]).columns\n",
    "X_train_numeric = X_train[numeric_cols]\n",
    "X_test_numeric = X_test[numeric_cols]\n",
    "\n",
    "\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "rf_grid = GridSearchCV(\n",
    "    estimator=RandomForestClassifier(),\n",
    "    param_grid=rf_param_grid,\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_grid.fit(X_train_numeric, y_train)\n",
    "print(f\"‚úÖ Melhores par√¢metros RandomForest: {rf_grid.best_params_}\")\n",
    "print(f\"‚úÖ Score CV: {rf_grid.best_score_:.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a66e63d",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08b53f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = X_train.select_dtypes(include=[np.number]).columns\n",
    "X_train_numeric = X_train[numeric_cols]\n",
    "X_test_numeric = X_test[numeric_cols]\n",
    "\n",
    "xgb_param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 6, 10],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "xgb_grid = GridSearchCV(\n",
    "    estimator=XGBClassifier(use_label_encoder=False, eval_metric='mlogloss'),\n",
    "    param_grid=xgb_param_grid,\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "xgb_grid.fit(X_train_numeric, y_train)\n",
    "print(f\"‚úÖ Melhores par√¢metros XGBoost: {xgb_grid.best_params_}\")\n",
    "print(f\"‚úÖ Score CV: {xgb_grid.best_score_:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81c1730",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc736d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),  # preencher NaN com m√©dia da coluna\n",
    "    ('scaler', StandardScaler()),                  # escalar dados\n",
    "    ('svm', SVC(random_state=42))\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train_numeric, y_train)\n",
    "print(f\"‚úÖ Score treino: {pipeline.score(X_train_numeric, y_train):.3f}\")\n",
    "print(f\"‚úÖ Score teste: {pipeline.score(X_test_numeric, y_test):.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hotel-venv",
   "language": "python",
   "name": "hotel-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
