# **Hotel-Booking-Cancellation-Forecast**

Pipeline End-to-End: IoT â†’ Data Lake â†’ Banco â†’ Modelagem â†’ MLflow â†’ Dashboard

Este projeto implementa um pipeline completo de **Engenharia de Dados, IoT e Machine Learning** para previsÃ£o de cancelamento de reservas de hotel.
O fluxo integra **ThingsBoard**, **FastAPI**, **MinIO**, **JupyterLab**, **MLflow**, alÃ©m da reproduÃ§Ã£o e expansÃ£o de um paper de referÃªncia na Ã¡rea.

O objetivo final Ã© criar uma soluÃ§Ã£o **automatizada e reprodutÃ­vel** que:

* coleta dados brutos via IoT,
* armazena e organiza em um data lake,
* processa e modela,
* versiona modelos,
* e exibe resultados em dashboards consolidados.

---

# ðŸ‘¥ Equipe


| Nome                  | E-mail                                                                  | GitHub                                |
| --------------------- | ----------------------------------------------------------------------- | ------------------------------------- |
| **JoÃ£o Marcelo**      | [jmnfa@cesar.school](mailto:jmnfa@cesar.school)                         | â€”                                     |
| **Vinicius Ventura**  | [vini.ventura999@gmail.com](mailto:vini.ventura999@gmail.com)           | â€”                                     |
| **Gabriel MagalhÃ£es** | [gabrielgrmagalhaes@outlook.com](mailto:gabrielgrmagalhaes@outlook.com) | â€”                                     |
| **Arthur Freire**     | [arthurduartefreire@gmail.com](mailto:arthurduartefreire@gmail.com)     | â€”                                     |
| **Igor Wanderley**    | [igorfwds@hotmail.com](mailto:igorfwds@hotmail.com)                     | â€”                                     |
| **Laura Vidal**       | [lauravidal@outlook.com](mailto:lauravidal@outlook.com)                 | â€”                                     |


InstituiÃ§Ã£o: InstituiÃ§Ã£o: CESAR School
Disciplina: Aprendizado de MÃ¡quina - 2025.2

---

# **Arquitetura do Projeto**

Todo o pipeline roda via **Docker Compose**, orquestrando os seguintes serviÃ§os:

### **1. Script Python â†’ ThingsBoard**

Envia dados simulados ou coletados de sensores para o ThingsBoard via MQTT/HTTP.

### **2. FastAPI â†’ Bucket**

API responsÃ¡vel por consumir dados do ThingsBoard e armazenÃ¡-los no bucket â€œrawâ€ do Data Lake.

### **3. Bucket â†’ MinIO (S3)**

O bucket armazena os dados brutos e processados.
A API ou scripts internos movem os dados para estruturas organizadas dentro do MinIO.

### **4. MinIO â†’ JupyterLab**

Notebooks utilizam o MinIO como fonte Ãºnica de verdade para anÃ¡lise exploratÃ³ria, limpeza, preparaÃ§Ã£o e modelagem.

### **5. ReproduÃ§Ã£o do Paper + ContribuiÃ§Ãµes**

A pipeline inclui um notebook dedicado Ã  reproduÃ§Ã£o do paper utilizado como referÃªncia, seguido das melhorias e extensÃµes propostas pelo time.

### **6. Versionamento de Modelos no MLflow**

Todos os experimentos e mÃ©tricas sÃ£o armazenados no MLflow Tracking Server.

### **7. Dashboard final**

Dashboard unificado consumindo:

* dados brutos do ThingsBoard (tempo real),
* previsÃµes dos modelos registrados no MLflow.

---

# **Estrutura de Pastas**

```
/
â”œâ”€â”€ api/                                # FastAPI responsÃ¡vel por enviar dados ao bucket/MinIO
â”‚   â”œâ”€â”€ __pycache__/                    # Cache interno do Python
â”‚   â”œâ”€â”€ main.py                         # API principal (ingestÃ£o / integraÃ§Ã£o ThingsBoard -> Bucket)
â”‚   â””â”€â”€ data/
â”‚       â””â”€â”€ hotel_bookings.csv          # Dataset base utilizado pela API
â”‚
â”œâ”€â”€ iot/
â”‚   â””â”€â”€ send_csv_to_thingsboard.py      # Script Python que envia dados CSV diretamente ao ThingsBoard
â”‚
â”œâ”€â”€ mlruns/                             # DiretÃ³rio gerado automaticamente pelo MLflow Tracking
â”‚   â”œâ”€â”€ .trash/                         # Experimentos deletados
â”‚   â”œâ”€â”€ 0/                              # Experimento "Default"
â”‚   â”œâ”€â”€ <run_id_1>/                     # ExecuÃ§Ãµes rastreadas
â”‚   â”œâ”€â”€ <run_id_2>/
â”‚   â””â”€â”€ models/                         # Artefatos de modelos versionados
â”‚
â”œâ”€â”€ notebooks/                          # Notebooks Jupyter para anÃ¡lise, modelagem e paper
â”‚   â”œâ”€â”€ 01_eda_baseline.ipynb           # AnÃ¡lise exploratÃ³ria inicial
â”‚   â””â”€â”€ 02_deep_analysis.ipynb          # AnÃ¡lise aprofundada, testes e modelagem
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ mlflow_experiments/             # Scripts de experimentaÃ§Ã£o e registro no MLflow
â”‚   â””â”€â”€ validate_neondb.py              # ValidaÃ§Ã£o do banco NeonDB / infraestrutura externa (se aplicÃ¡vel)
â”‚
â”œâ”€â”€ venv/                               # Ambiente virtual Python usado no VS Code
â”‚   â”œâ”€â”€ Include/
â”‚   â”œâ”€â”€ Lib/
â”‚   â”œâ”€â”€ Scripts/
â”‚   â””â”€â”€ etc/
â”‚
â”œâ”€â”€ .env                                # VariÃ¡veis de ambiente (ThingsBoard, Bucket, MLflow, MinIO)
â”œâ”€â”€ .gitignore
â”œâ”€â”€ LICENSE
â”œâ”€â”€ README.md                           # DocumentaÃ§Ã£o do projeto
â””â”€â”€ requirements.txt                    # DependÃªncias Python
```

# **Como Executar o Projeto**

Abaixo estÃ¡ o guia completo para levantar a infraestrutura, coletar dados, treinar modelos e visualizar resultados.

---

## **PrÃ©-requisitos**

* Docker Desktop instalado e rodando
* Git (opcional)
* Python 3.9+ (caso execute o script ThingsBoard fora do Docker)

---

# **Passo 1: Subir a Infraestrutura (Docker)**

Na raiz do projeto (onde estÃ¡ o `docker-compose.yml`):

```bash
docker-compose up -d --build
```

Verifique se todos os containers estÃ£o ativos:

```bash
docker ps
```

---

# **Passo 2: Enviar Dados para o ThingsBoard**

Execute o script localizado em `/scripts`:

```bash
python scripts/send_to_thingsboard.py
```

Certifique-se de ter configurado corretamente o **Device Token** do ThingsBoard.

Painel do ThingsBoard:
**[http://localhost:8080](http://localhost:8080)**

---

# **Passo 3: IngestÃ£o de Dados (FastAPI â†’ Bucket)**

Acesse a documentaÃ§Ã£o da API:

**[http://localhost:8000/docs](http://localhost:8000/docs)**

Use o endpoint responsÃ¡vel por capturar as mÃ©tricas do ThingsBoard e enviÃ¡-las para o bucket.

Exemplo:
`POST /ingest/thingsboard`

Se receber 200 OK â†’ dados armazenados com sucesso.

---

# **Passo 4: Armazenamento no MinIO**

Acesse o console:

**[http://localhost:9001](http://localhost:9001)**
UsuÃ¡rio: `minioadmin`
Senha: `minioadmin`

Verifique se os dados brutos foram armazenados no bucket correspondente.

---

# **Passo 5: Notebooks (EDA, Modelagem e Paper)**

Acesse:

**[http://localhost:8888](http://localhost:8888)**

Abra os notebooks em `/notebooks`:

* `eda_and_cleaning.ipynb`
* `model_training.ipynb`
* `paper_reproduction.ipynb`
* `contributions.ipynb`

Executar tudo sequencialmente.

### SaÃ­das esperadas:

* GrÃ¡ficos e relatÃ³rios em `/notebooks/outputs`
* Modelos registrados no MLflow
* Dados tratados enviados ao MinIO

---

# **Passo 6: Versionamento no MLflow**

Acesse:

**[http://localhost:5000](http://localhost:5000)**

Aqui vocÃª poderÃ¡:

* acompanhar mÃ©tricas,
* comparar experimentos,
* armazenar modelos,
* gerar artefatos.

Experimento principal:
**Hotel_Booking_Cancellation_Forecast**

---

# **Passo 7: Dashboard Final**

O dashboard integra:

* dados brutos diretamente do ThingsBoard
* previsÃµes dos modelos (via MLflow ou API)
* visualizaÃ§Ãµes agregadas
* mÃ©tricas de cancelamento

Acesse a interface no container correspondente (ex.: Streamlit ou Grafana, dependendo da implementaÃ§Ã£o).

---

# **Encerrando a ExecuÃ§Ã£o**

Para parar tudo:

```bash
docker-compose down
```
