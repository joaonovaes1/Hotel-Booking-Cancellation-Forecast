{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5f6ace6",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eebf4b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sqlalchemy import create_engine\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split  # [web:1]\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.width', None)       \n",
    "pd.set_option('display.max_colwidth', None)   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa9e90d",
   "metadata": {},
   "source": [
    "## Cria√ß√£o do DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "899ce649",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv() \n",
    "database_url = os.getenv(\"NEON_DATABASE_URL\")\n",
    "\n",
    "engine = create_engine(database_url)\n",
    "query = \"SELECT * FROM hotel_bookings\"\n",
    "\n",
    "df = pd.read_sql(query, engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f7f436",
   "metadata": {},
   "source": [
    "### Separa√ß√£o dos Dados para Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b416b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valida√ß√£o salva: 17909 linhas\n"
     ]
    }
   ],
   "source": [
    "df_modeling, df_validation = train_test_split(\n",
    "    df, test_size=0.15, stratify=df[\"is_canceled\"], random_state=42\n",
    ")\n",
    "\n",
    "df_validation.to_csv(\"../data/hotel_bookings_validation.csv\", index=False)\n",
    "print(f\"Valida√ß√£o salva: {len(df_validation)} linhas\")\n",
    "\n",
    "df = df_modeling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ea25e7",
   "metadata": {},
   "source": [
    "### EDA\n",
    "\n",
    "\"Preprocessing includes lumping infrequent categories of the categorical predictor\n",
    "Country (originally with 126 levels or countries) into 11 levels (CN, DEU, ESP, FRA, GBR,\n",
    "IRL, NLD, PRT, USA, NULL and OTHER). The categorical predictor ReservedRoomType has\n",
    "11 levels, and the categorical predictor AssignedRoomType has 10 levels; the levels of these\n",
    "two predictors were lumped into a total of seven categories to increase the counts of\n",
    "infrequent levels.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72140387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ANTES DO PR√â-PROCESSAMENTO ===\n",
      "Country n√≠veis √∫nicos: 172 ['SWE' 'NZL' 'PRT' 'FRA' 'GBR' 'NLD' 'USA' 'DEU' 'ESP' 'ISR']\n",
      "ReservedRoomType n√≠veis √∫nicos: 10\n",
      "AssignedRoomType n√≠veis √∫nicos: 12\n",
      "\n",
      "=== DEPOIS DO PR√â-PROCESSAMENTO ===\n",
      "Country n√≠veis √∫nicos: 11 ['CN', 'DEU', 'ESP', 'FRA', 'GBR', 'IRL', 'NLD', 'NULL', 'OTHER', 'PRT', 'USA']\n",
      "ReservedRoomType n√≠veis √∫nicos: 7 ['A', 'B', 'C', 'D', 'E', 'F', 'OTHER']\n",
      "AssignedRoomType n√≠veis √∫nicos: 7 ['A', 'B', 'C', 'D', 'E', 'F', 'OTHER']\n",
      "\n",
      "Distribui√ß√£o Country (top 11):\n",
      "country\n",
      "PRT      41369\n",
      "OTHER    19572\n",
      "GBR      10319\n",
      "FRA       8808\n",
      "ESP       7262\n",
      "DEU       6202\n",
      "IRL       2875\n",
      "NLD       1788\n",
      "USA       1781\n",
      "CN        1088\n",
      "NULL       417\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def preprocess_hotel_categories(df):\n",
    "    \"\"\"\n",
    "    Replica o pr√©-processamento do paper:\n",
    "    - Country: 126 n√≠veis -> 11 n√≠veis (CN, DEU, ESP, FRA, GBR, IRL, NLD, PRT, USA, NULL, OTHER)\n",
    "    - ReservedRoomType (11 n√≠veis) e AssignedRoomType (10 n√≠veis) -> 7 categorias totais combinadas\n",
    "    \"\"\"\n",
    "    \n",
    "    df_processed = df.copy()\n",
    "    \n",
    "    priority_countries = ['CN', 'DEU', 'ESP', 'FRA', 'GBR', 'IRL', 'NLD', 'PRT', 'USA']\n",
    "    \n",
    "    def lump_country(country):\n",
    "        if pd.isna(country):\n",
    "            return 'NULL'\n",
    "        elif country in priority_countries:\n",
    "            return country\n",
    "        else:\n",
    "            return 'OTHER'\n",
    "    \n",
    "    df_processed['country'] = df_processed['country'].apply(lump_country)\n",
    "    \n",
    "    common_room_types = ['A', 'B', 'C', 'D', 'E', 'F']  # Baseado em datasets t√≠picos\n",
    "    \n",
    "    def lump_room_type(room):\n",
    "        if pd.isna(room):\n",
    "            return 'NULL'\n",
    "        elif room in common_room_types:\n",
    "            return room\n",
    "        else:\n",
    "            return 'OTHER'\n",
    "    \n",
    "    df_processed['reserved_room_type'] = df_processed['reserved_room_type'].apply(lump_room_type)\n",
    "    df_processed['assigned_room_type'] = df_processed['assigned_room_type'].apply(lump_room_type)\n",
    "    \n",
    "    return df_processed\n",
    "\n",
    "# APLICAR O PR√â-PROCESSAMENTO\n",
    "print(\"=== ANTES DO PR√â-PROCESSAMENTO ===\")\n",
    "print(\"Country n√≠veis √∫nicos:\", df['country'].nunique(), df['country'].unique()[:10])\n",
    "print(\"ReservedRoomType n√≠veis √∫nicos:\", df['reserved_room_type'].nunique())\n",
    "print(\"AssignedRoomType n√≠veis √∫nicos:\", df['assigned_room_type'].nunique())\n",
    "\n",
    "# Executar pr√©-processamento\n",
    "df = preprocess_hotel_categories(df)\n",
    "\n",
    "print(\"\\n=== DEPOIS DO PR√â-PROCESSAMENTO ===\")\n",
    "print(\"Country n√≠veis √∫nicos:\", df['country'].nunique(), sorted(df['country'].unique()))\n",
    "print(\"ReservedRoomType n√≠veis √∫nicos:\", df['reserved_room_type'].nunique(), sorted(df['reserved_room_type'].unique()))\n",
    "print(\"AssignedRoomType n√≠veis √∫nicos:\", df['assigned_room_type'].nunique(), sorted(df['assigned_room_type'].unique()))\n",
    "\n",
    "print(\"\\nDistribui√ß√£o Country (top 11):\")\n",
    "print(df['country'].value_counts().head(11))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9ead5a",
   "metadata": {},
   "source": [
    "### Pre Processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce239730",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['arrival_date_month'] = pd.Categorical(df['arrival_date_month'], \n",
    "                                          categories=[\"January\",\"February\",\"March\",\n",
    "                                                      \"April\",\"May\",\"June\",\"July\",\"August\",\n",
    "                                                      \"September\",\"October\",\"November\",\"December\"], \n",
    "                                          ordered=True)\n",
    "\n",
    "df['arrival_date_day_of_month'] = df['arrival_date_day_of_month'].astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fa1ee7",
   "metadata": {},
   "source": [
    "### Divis√£o de Treino e Teste\n",
    "    \"75% training set and a 25% test set to estimate the performance of the machine learning algorithms\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3dc986c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71d9d5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['is_canceled'])\n",
    "y = df['is_canceled']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "635f19bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "968382f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (81184, 31), y_train: (81184,)\n",
      "X_test: (20297, 31), y_test: (20297,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "print(f\"X_test: {X_test.shape}, y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a452804d",
   "metadata": {},
   "source": [
    "### Normaliza√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68780cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç COLUNAS COM MUITAS CATEGORIAS √öNICAS:\n",
      "‚ùå reservation_status_date: 913 n√≠veis √∫nicos\n",
      "   Amostra: ['2016-10-06' '2015-07-02' '2016-04-27' '2015-10-16' '2016-09-27']\n",
      "\n",
      "üìÖ Convertendo reservation_status_date para num√©rico...\n",
      "üìÖ Convertendo reservation_status_date para num√©rico...\n",
      "\n",
      "‚úÖ Ap√≥s tratamento:\n",
      "Cont√≠nuas: ['lead_time', 'arrival_date_year', 'arrival_date_week_number', 'arrival_date_day_of_month', 'stays_in_weekend_nights', 'stays_in_week_nights', 'adults', 'children', 'babies', 'is_repeated_guest', 'previous_cancellations', 'previous_bookings_not_canceled', 'booking_changes', 'agent', 'company', 'days_in_waiting_list', 'adr', 'required_car_parking_spaces', 'total_of_special_requests', 'reservation_status_date']\n",
      "Categ√≥ricas: ['hotel', 'meal', 'country', 'market_segment', 'distribution_channel', 'reserved_room_type', 'assigned_room_type', 'deposit_type', 'customer_type', 'reservation_status']\n",
      "\n",
      "‚úÖ X_train processado: (81184, 65)\n",
      "‚úÖ X_test processado: (20297, 65)\n"
     ]
    }
   ],
   "source": [
    "# 1. DIAGN√ìSTICO: Identificar qual coluna tem datas\n",
    "print(\"üîç COLUNAS COM MUITAS CATEGORIAS √öNICAS:\")\n",
    "for col in X_train.select_dtypes(include=['object']).columns:\n",
    "    unique_count = X_train[col].nunique()\n",
    "    if unique_count > 20:  # Suspeita de datas\n",
    "        print(f\"‚ùå {col}: {unique_count} n√≠veis √∫nicos\")\n",
    "        print(f\"   Amostra: {X_train[col].unique()[:5]}\")\n",
    "        print()\n",
    "\n",
    "# 2. TRATAR COLUNAS DE DATA PROBLEM√ÅTICAS\n",
    "def fix_date_columns(df):\n",
    "    df_fixed = df.copy()\n",
    "    \n",
    "    # Converter colunas suspeitas de data para num√©ricas ou remover\n",
    "    date_suspect_cols = []\n",
    "    for col in df_fixed.select_dtypes(include=['object']).columns:\n",
    "        if df_fixed[col].nunique() > 20:  # Muitas categorias = provavelmente data\n",
    "            try:\n",
    "                # Tentar converter para datetime e extrair features\n",
    "                pd.to_datetime(df_fixed[col], errors='coerce')\n",
    "                print(f\"üìÖ Convertendo {col} para num√©rico...\")\n",
    "                df_fixed[col] = pd.to_datetime(df_fixed[col], errors='coerce').dt.dayofyear\n",
    "            except:\n",
    "                # Se n√£o conseguir, remover a coluna\n",
    "                print(f\"üóëÔ∏è Removendo {col} (demasiadas categorias)\")\n",
    "                df_fixed = df_fixed.drop(columns=[col])\n",
    "    \n",
    "    return df_fixed\n",
    "\n",
    "# APLICAR TRATAMENTO\n",
    "X_train_fixed = fix_date_columns(X_train)\n",
    "X_test_fixed = fix_date_columns(X_test)\n",
    "\n",
    "# 3. AGORA O PREPROCESSADOR FUNCIONA\n",
    "continuous_cols = X_train_fixed.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_cols = X_train_fixed.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "print(f\"\\n‚úÖ Ap√≥s tratamento:\")\n",
    "print(\"Cont√≠nuas:\", continuous_cols)\n",
    "print(\"Categ√≥ricas:\", categorical_cols)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', MinMaxScaler(), continuous_cols),\n",
    "        ('cat', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore'), categorical_cols)\n",
    "    ])\n",
    "\n",
    "# FIT E TRANSFORM\n",
    "X_train_processed = preprocessor.fit_transform(X_train_fixed)\n",
    "X_test_processed = preprocessor.transform(X_test_fixed)\n",
    "\n",
    "print(f\"\\n‚úÖ X_train processado: {X_train_processed.shape}\")\n",
    "print(f\"‚úÖ X_test processado: {X_test_processed.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04060780",
   "metadata": {},
   "source": [
    "### Treinamento dos Modelos e Otimiza√ß√£o dos hiperpar√¢mtros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde57e96",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75c77000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Melhores par√¢metros RandomForest: {'bootstrap': True, 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "‚úÖ Score CV: 0.864\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "numeric_cols = X_train.select_dtypes(include=[np.number]).columns\n",
    "X_train_numeric = X_train[numeric_cols]\n",
    "X_test_numeric = X_test[numeric_cols]\n",
    "\n",
    "\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "rf_grid = GridSearchCV(\n",
    "    estimator=RandomForestClassifier(),\n",
    "    param_grid=rf_param_grid,\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_grid.fit(X_train_numeric, y_train)\n",
    "print(f\"‚úÖ Melhores par√¢metros RandomForest: {rf_grid.best_params_}\")\n",
    "print(f\"‚úÖ Score CV: {rf_grid.best_score_:.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a66e63d",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f08b53f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marce\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [11:25:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Melhores par√¢metros XGBoost: {'colsample_bytree': 1.0, 'learning_rate': 0.2, 'max_depth': 10, 'n_estimators': 200, 'subsample': 0.8}\n",
      "‚úÖ Score CV: 0.858\n"
     ]
    }
   ],
   "source": [
    "numeric_cols = X_train.select_dtypes(include=[np.number]).columns\n",
    "X_train_numeric = X_train[numeric_cols]\n",
    "X_test_numeric = X_test[numeric_cols]\n",
    "\n",
    "xgb_param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 6, 10],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "xgb_grid = GridSearchCV(\n",
    "    estimator=XGBClassifier(use_label_encoder=False, eval_metric='mlogloss'),\n",
    "    param_grid=xgb_param_grid,\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "xgb_grid.fit(X_train_numeric, y_train)\n",
    "print(f\"‚úÖ Melhores par√¢metros XGBoost: {xgb_grid.best_params_}\")\n",
    "print(f\"‚úÖ Score CV: {xgb_grid.best_score_:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81c1730",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc736d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Score treino: 0.786\n",
      "‚úÖ Score teste: 0.782\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),  # preencher NaN com m√©dia da coluna\n",
    "    ('scaler', StandardScaler()),                  # escalar dados\n",
    "    ('svm', SVC(random_state=42))\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train_numeric, y_train)\n",
    "print(f\"‚úÖ Score treino: {pipeline.score(X_train_numeric, y_train):.3f}\")\n",
    "print(f\"‚úÖ Score teste: {pipeline.score(X_test_numeric, y_test):.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d08d2c9",
   "metadata": {},
   "source": [
    "### Terceiro Ciclo (novo dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "27758bc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hotel</th>\n",
       "      <th>is_canceled</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>arrival_date_year</th>\n",
       "      <th>arrival_date_month</th>\n",
       "      <th>arrival_date_week_number</th>\n",
       "      <th>arrival_date_day_of_month</th>\n",
       "      <th>stays_in_weekend_nights</th>\n",
       "      <th>stays_in_week_nights</th>\n",
       "      <th>adults</th>\n",
       "      <th>children</th>\n",
       "      <th>babies</th>\n",
       "      <th>meal</th>\n",
       "      <th>country</th>\n",
       "      <th>market_segment</th>\n",
       "      <th>distribution_channel</th>\n",
       "      <th>is_repeated_guest</th>\n",
       "      <th>previous_cancellations</th>\n",
       "      <th>previous_bookings_not_canceled</th>\n",
       "      <th>reserved_room_type</th>\n",
       "      <th>assigned_room_type</th>\n",
       "      <th>booking_changes</th>\n",
       "      <th>deposit_type</th>\n",
       "      <th>agent</th>\n",
       "      <th>company</th>\n",
       "      <th>days_in_waiting_list</th>\n",
       "      <th>customer_type</th>\n",
       "      <th>adr</th>\n",
       "      <th>required_car_parking_spaces</th>\n",
       "      <th>total_of_special_requests</th>\n",
       "      <th>reservation_status</th>\n",
       "      <th>reservation_status_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>342</td>\n",
       "      <td>2015</td>\n",
       "      <td>July</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>BB</td>\n",
       "      <td>PRT</td>\n",
       "      <td>Direct</td>\n",
       "      <td>Direct</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>3</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>2015-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>737</td>\n",
       "      <td>2015</td>\n",
       "      <td>July</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>BB</td>\n",
       "      <td>PRT</td>\n",
       "      <td>Direct</td>\n",
       "      <td>Direct</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>4</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>2015-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2015</td>\n",
       "      <td>July</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>BB</td>\n",
       "      <td>GBR</td>\n",
       "      <td>Direct</td>\n",
       "      <td>Direct</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>2015-07-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>2015</td>\n",
       "      <td>July</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>BB</td>\n",
       "      <td>GBR</td>\n",
       "      <td>Corporate</td>\n",
       "      <td>Corporate</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>304.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>2015-07-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Resort Hotel</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>2015</td>\n",
       "      <td>July</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>BB</td>\n",
       "      <td>GBR</td>\n",
       "      <td>Online TA</td>\n",
       "      <td>TA/TO</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>No Deposit</td>\n",
       "      <td>240.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Transient</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Check-Out</td>\n",
       "      <td>2015-07-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          hotel  is_canceled  lead_time  arrival_date_year arrival_date_month  \\\n",
       "0  Resort Hotel            0        342               2015               July   \n",
       "1  Resort Hotel            0        737               2015               July   \n",
       "2  Resort Hotel            0          7               2015               July   \n",
       "3  Resort Hotel            0         13               2015               July   \n",
       "4  Resort Hotel            0         14               2015               July   \n",
       "\n",
       "   arrival_date_week_number  arrival_date_day_of_month  \\\n",
       "0                        27                          1   \n",
       "1                        27                          1   \n",
       "2                        27                          1   \n",
       "3                        27                          1   \n",
       "4                        27                          1   \n",
       "\n",
       "   stays_in_weekend_nights  stays_in_week_nights  adults  children  babies  \\\n",
       "0                        0                     0       2       0.0       0   \n",
       "1                        0                     0       2       0.0       0   \n",
       "2                        0                     1       1       0.0       0   \n",
       "3                        0                     1       1       0.0       0   \n",
       "4                        0                     2       2       0.0       0   \n",
       "\n",
       "  meal country market_segment distribution_channel  is_repeated_guest  \\\n",
       "0   BB     PRT         Direct               Direct                  0   \n",
       "1   BB     PRT         Direct               Direct                  0   \n",
       "2   BB     GBR         Direct               Direct                  0   \n",
       "3   BB     GBR      Corporate            Corporate                  0   \n",
       "4   BB     GBR      Online TA                TA/TO                  0   \n",
       "\n",
       "   previous_cancellations  previous_bookings_not_canceled reserved_room_type  \\\n",
       "0                       0                               0                  C   \n",
       "1                       0                               0                  C   \n",
       "2                       0                               0                  A   \n",
       "3                       0                               0                  A   \n",
       "4                       0                               0                  A   \n",
       "\n",
       "  assigned_room_type  booking_changes deposit_type  agent  company  \\\n",
       "0                  C                3   No Deposit    NaN      NaN   \n",
       "1                  C                4   No Deposit    NaN      NaN   \n",
       "2                  C                0   No Deposit    NaN      NaN   \n",
       "3                  A                0   No Deposit  304.0      NaN   \n",
       "4                  A                0   No Deposit  240.0      NaN   \n",
       "\n",
       "   days_in_waiting_list customer_type   adr  required_car_parking_spaces  \\\n",
       "0                     0     Transient   0.0                            0   \n",
       "1                     0     Transient   0.0                            0   \n",
       "2                     0     Transient  75.0                            0   \n",
       "3                     0     Transient  75.0                            0   \n",
       "4                     0     Transient  98.0                            0   \n",
       "\n",
       "   total_of_special_requests reservation_status reservation_status_date  \n",
       "0                          0          Check-Out              2015-07-01  \n",
       "1                          0          Check-Out              2015-07-01  \n",
       "2                          0          Check-Out              2015-07-02  \n",
       "3                          0          Check-Out              2015-07-02  \n",
       "4                          1          Check-Out              2015-07-03  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database_url = os.getenv(\"NEON_DATABASE_URL\")\n",
    "\n",
    "engine = create_engine(database_url)\n",
    "query = \"SELECT * FROM hotel_bookings\"\n",
    "\n",
    "df1 = pd.read_sql(query, engine)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b04ed0",
   "metadata": {},
   "source": [
    "#### Resort Hotel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "654b57e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resort Hotel (40060, 32)\n"
     ]
    }
   ],
   "source": [
    "hotel_alvo = \"Resort Hotel\" \n",
    "\n",
    "df_hotel = df1[df1[\"hotel\"] == hotel_alvo].copy()\n",
    "print(hotel_alvo, df_hotel.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d37beec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y value_counts:\n",
      "is_canceled\n",
      "0    28938\n",
      "1    11122\n",
      "Name: count, dtype: int64\n",
      "\n",
      "X shape: (40060, 29)\n",
      "X columns: ['hotel', 'lead_time', 'arrival_date_year', 'arrival_date_month', 'arrival_date_week_number', 'arrival_date_day_of_month', 'stays_in_weekend_nights', 'stays_in_week_nights', 'adults', 'children', 'babies', 'meal', 'country', 'market_segment', 'distribution_channel', 'is_repeated_guest', 'previous_cancellations', 'previous_bookings_not_canceled', 'reserved_room_type', 'assigned_room_type', 'booking_changes', 'deposit_type', 'agent', 'company', 'days_in_waiting_list', 'customer_type', 'adr', 'required_car_parking_spaces', 'total_of_special_requests']\n"
     ]
    }
   ],
   "source": [
    "y = df_hotel['is_canceled']\n",
    "\n",
    "cols_to_drop = ['is_canceled', 'reservation_status', 'reservation_status_date']\n",
    "X = df_hotel.drop(columns=cols_to_drop)\n",
    "\n",
    "print(\"y value_counts:\")\n",
    "print(y.value_counts())\n",
    "print(\"\\nX shape:\", X.shape)\n",
    "print(\"X columns:\", X.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9aef1025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes ap√≥s split:\n",
      "X_train: (30045, 29) y_train: (30045,)\n",
      "X_test : (10015, 29) y_test : (10015,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Shapes ap√≥s split:\")\n",
    "print(\"X_train:\", X_train.shape, \"y_train:\", y_train.shape)\n",
    "print(\"X_test :\", X_test.shape, \"y_test :\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ae3de0e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marce\\AppData\\Local\\Temp\\ipykernel_13360\\3254778212.py:6: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  conv = pd.to_datetime(df_fixed[col], errors='coerce')\n",
      "C:\\Users\\marce\\AppData\\Local\\Temp\\ipykernel_13360\\3254778212.py:6: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  conv = pd.to_datetime(df_fixed[col], errors='coerce')\n",
      "c:\\Users\\marce\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:246: UserWarning: Found unknown categories in columns [3, 5, 7] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_processed: (30045, 182)\n",
      "X_test_processed : (10015, 182)\n"
     ]
    }
   ],
   "source": [
    "def fix_date_columns(df_raw):\n",
    "    df_fixed = df_raw.copy()\n",
    "    for col in df_fixed.select_dtypes(include=['object']).columns:\n",
    "        if df_fixed[col].nunique() > 20:\n",
    "            try:\n",
    "                conv = pd.to_datetime(df_fixed[col], errors='coerce')\n",
    "                if conv.notna().sum() > 0:\n",
    "                    print(f\"üìÖ Convertendo {col} para dayofyear...\")\n",
    "                    df_fixed[col] = conv.dt.dayofyear\n",
    "            except Exception:\n",
    "                print(f\"üóëÔ∏è Removendo {col}\")\n",
    "                df_fixed = df_fixed.drop(columns=[col])\n",
    "    return df_fixed\n",
    "\n",
    "X_train_fixed = fix_date_columns(X_train)\n",
    "X_test_fixed = fix_date_columns(X_test)\n",
    "\n",
    "continuous_cols = X_train_fixed.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_cols = X_train_fixed.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', MinMaxScaler(), continuous_cols),\n",
    "        ('cat', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore'), categorical_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "X_train_processed = preprocessor.fit_transform(X_train_fixed)\n",
    "X_test_processed = preprocessor.transform(X_test_fixed)\n",
    "\n",
    "print(\"X_train_processed:\", X_train_processed.shape)\n",
    "print(\"X_test_processed :\", X_test_processed.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446c7425",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "92ceb352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "RF best: {'bootstrap': True, 'class_weight': 'balanced', 'max_depth': 15, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [200],\n",
    "    'max_depth': [10, 15],\n",
    "    'min_samples_split': [5, 10],\n",
    "    'min_samples_leaf': [2, 4],\n",
    "    'bootstrap': [True],\n",
    "    'class_weight': ['balanced']\n",
    "}\n",
    "\n",
    "rf_grid = GridSearchCV(\n",
    "    estimator=RandomForestClassifier(random_state=42, n_jobs=-1),\n",
    "    param_grid=rf_param_grid,\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "rf_grid.fit(X_train_processed, y_train)\n",
    "rf_best = rf_grid.best_estimator_\n",
    "print(\"RF best:\", rf_grid.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "559c5d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF Treino:\n",
      "  OA: 0.893\n",
      "  P_1: 0.749\n",
      "  R_1: 0.925\n",
      "  F1_1: 0.827\n",
      "  P_0: 0.968\n",
      "  R_0: 0.881\n",
      "  F1_0: 0.922\n",
      "\n",
      "RF Teste:\n",
      "  OA: 0.876\n",
      "  P_1: 0.728\n",
      "  R_1: 0.881\n",
      "  F1_1: 0.797\n",
      "  P_0: 0.950\n",
      "  R_0: 0.874\n",
      "  F1_0: 0.910\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def metrics_paper(y_true, y_pred):\n",
    "    oa = float(accuracy_score(y_true, y_pred))\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        y_true, y_pred, average=None, labels=[1, 0]\n",
    "    )\n",
    "    return {\n",
    "        \"OA\": float(oa),\n",
    "        \"P_1\": float(precision[0]),\n",
    "        \"R_1\": float(recall[0]),\n",
    "        \"F1_1\": float(f1[0]),\n",
    "        \"P_0\": float(precision[1]),\n",
    "        \"R_0\": float(recall[1]),\n",
    "        \"F1_0\": float(f1[1]),\n",
    "    }\n",
    "\n",
    "y_rf_train = rf_best.predict(X_train_processed)\n",
    "y_rf_test = rf_best.predict(X_test_processed)\n",
    "\n",
    "m_train = metrics_paper(y_train, y_rf_train)\n",
    "m_test = metrics_paper(y_test, y_rf_test)\n",
    "\n",
    "print(\"RF Treino:\")\n",
    "for k, v in m_train.items():\n",
    "    print(f\"  {k}: {v:.3f}\")\n",
    "\n",
    "print(\"\\nRF Teste:\")\n",
    "for k, v in m_test.items():\n",
    "    print(f\"  {k}: {v:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f13f47eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - OA teste: 0.876\n"
     ]
    }
   ],
   "source": [
    "print(f\"Random Forest - OA teste: {m_test['OA']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555a1c70",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "56ee4e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB Treino:\n",
      "  OA: 0.963\n",
      "  P_1: 0.932\n",
      "  R_1: 0.933\n",
      "  F1_1: 0.933\n",
      "  P_0: 0.974\n",
      "  R_0: 0.974\n",
      "  F1_0: 0.974\n",
      "\n",
      "XGB Teste:\n",
      "  OA: 0.907\n",
      "  P_1: 0.838\n",
      "  R_1: 0.825\n",
      "  F1_1: 0.831\n",
      "  P_0: 0.933\n",
      "  R_0: 0.939\n",
      "  F1_0: 0.936\n"
     ]
    }
   ],
   "source": [
    "xgb_param_grid = {\n",
    "    'n_estimators': [300, 500],\n",
    "    'max_depth': [3, 6],\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "xgb_grid = GridSearchCV(\n",
    "    estimator=XGBClassifier(\n",
    "        use_label_encoder=False,\n",
    "        eval_metric='logloss',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    param_grid=xgb_param_grid,\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "\n",
    "y_xgb_train = xgb_best.predict(X_train_processed)\n",
    "y_xgb_test = xgb_best.predict(X_test_processed)\n",
    "\n",
    "m_train_xgb = metrics_paper(y_train, y_xgb_train)\n",
    "m_test_xgb = metrics_paper(y_test, y_xgb_test)\n",
    "\n",
    "print(\"XGB Treino:\")\n",
    "for k, v in m_train_xgb.items():\n",
    "    print(f\"  {k}: {v:.3f}\")\n",
    "\n",
    "print(\"\\nXGB Teste:\")\n",
    "for k, v in m_test_xgb.items():\n",
    "    print(f\"  {k}: {v:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3313c1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost - OA teste: 0.907\n"
     ]
    }
   ],
   "source": [
    "print(f\"XGBoost - OA teste: {m_test_xgb['OA']:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf1ffef",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b3889f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs em X_train_svm: 0\n",
      "NaNs em X_test_svm : 0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "\n",
    "X_train_svm = imputer.fit_transform(X_train_processed)\n",
    "X_test_svm = imputer.transform(X_test_processed)\n",
    "\n",
    "print(\"NaNs em X_train_svm:\", np.isnan(X_train_svm).sum())\n",
    "print(\"NaNs em X_test_svm :\", np.isnan(X_test_svm).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "44b7a8fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "SVM best: {'C': 5, 'gamma': 'scale', 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "svm_param_grid = {\n",
    "    'C': [1, 5],\n",
    "    'gamma': ['scale', 0.1, 0.01],\n",
    "    'kernel': ['rbf']\n",
    "}\n",
    "\n",
    "svm_grid = GridSearchCV(\n",
    "    estimator=SVC(random_state=42),\n",
    "    param_grid=svm_param_grid,\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "svm_grid.fit(X_train_svm, y_train)\n",
    "svm_best = svm_grid.best_estimator_\n",
    "print(\"SVM best:\", svm_grid.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "46aba18d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Treino:\n",
      "  OA: 0.901\n",
      "  P_1: 0.839\n",
      "  R_1: 0.795\n",
      "  F1_1: 0.817\n",
      "  P_0: 0.923\n",
      "  R_0: 0.941\n",
      "  F1_0: 0.932\n",
      "\n",
      "SVM Teste:\n",
      "  OA: 0.878\n",
      "  P_1: 0.803\n",
      "  R_1: 0.743\n",
      "  F1_1: 0.772\n",
      "  P_0: 0.904\n",
      "  R_0: 0.930\n",
      "  F1_0: 0.917\n"
     ]
    }
   ],
   "source": [
    "y_svm_train = svm_best.predict(X_train_svm)\n",
    "y_svm_test = svm_best.predict(X_test_svm)\n",
    "\n",
    "m_train_svm = metrics_paper(y_train, y_svm_train)\n",
    "m_test_svm = metrics_paper(y_test, y_svm_test)\n",
    "\n",
    "print(\"SVM Treino:\")\n",
    "for k, v in m_train_svm.items():\n",
    "    print(f\"  {k}: {v:.3f}\")\n",
    "\n",
    "print(\"\\nSVM Teste:\")\n",
    "for k, v in m_test_svm.items():\n",
    "    print(f\"  {k}: {v:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85dd9126",
   "metadata": {},
   "source": [
    "#### City Hotel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3696db45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City Hotel (79330, 32)\n"
     ]
    }
   ],
   "source": [
    "hotel_alvo = \"City Hotel\" \n",
    "\n",
    "df_hotel = df1[df1[\"hotel\"] == hotel_alvo].copy()\n",
    "print(hotel_alvo, df_hotel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "297ba473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y value_counts:\n",
      "is_canceled\n",
      "0    46228\n",
      "1    33102\n",
      "Name: count, dtype: int64\n",
      "\n",
      "X shape: (79330, 29)\n",
      "X columns: ['hotel', 'lead_time', 'arrival_date_year', 'arrival_date_month', 'arrival_date_week_number', 'arrival_date_day_of_month', 'stays_in_weekend_nights', 'stays_in_week_nights', 'adults', 'children', 'babies', 'meal', 'country', 'market_segment', 'distribution_channel', 'is_repeated_guest', 'previous_cancellations', 'previous_bookings_not_canceled', 'reserved_room_type', 'assigned_room_type', 'booking_changes', 'deposit_type', 'agent', 'company', 'days_in_waiting_list', 'customer_type', 'adr', 'required_car_parking_spaces', 'total_of_special_requests']\n"
     ]
    }
   ],
   "source": [
    "y = df_hotel['is_canceled']\n",
    "\n",
    "cols_to_drop = ['is_canceled', 'reservation_status', 'reservation_status_date']\n",
    "X = df_hotel.drop(columns=cols_to_drop)\n",
    "\n",
    "print(\"y value_counts:\")\n",
    "print(y.value_counts())\n",
    "print(\"\\nX shape:\", X.shape)\n",
    "print(\"X columns:\", X.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4e228452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes ap√≥s split:\n",
      "X_train: (59497, 29) y_train: (59497,)\n",
      "X_test : (19833, 29) y_test : (19833,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Shapes ap√≥s split:\")\n",
    "print(\"X_train:\", X_train.shape, \"y_train:\", y_train.shape)\n",
    "print(\"X_test :\", X_test.shape, \"y_test :\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e866ca20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marce\\AppData\\Local\\Temp\\ipykernel_13360\\3191748202.py:6: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  conv = pd.to_datetime(df_fixed[col], errors='coerce')\n",
      "C:\\Users\\marce\\AppData\\Local\\Temp\\ipykernel_13360\\3191748202.py:6: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  conv = pd.to_datetime(df_fixed[col], errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "def fix_date_columns(df_raw):\n",
    "    df_fixed = df_raw.copy()\n",
    "    for col in df_fixed.select_dtypes(include=['object']).columns:\n",
    "        if df_fixed[col].nunique() > 20:\n",
    "            try:\n",
    "                conv = pd.to_datetime(df_fixed[col], errors='coerce')\n",
    "                if conv.notna().sum() > 0:\n",
    "                    print(f\"üìÖ Convertendo {col} para dayofyear...\")\n",
    "                    df_fixed[col] = conv.dt.dayofyear\n",
    "            except Exception:\n",
    "                print(f\"üóëÔ∏è Removendo {col}\")\n",
    "                df_fixed = df_fixed.drop(columns=[col])\n",
    "    return df_fixed\n",
    "\n",
    "X_train_fixed = fix_date_columns(X_train)\n",
    "X_test_fixed = fix_date_columns(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d747729",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a97af2ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "RF best (City): {'bootstrap': True, 'class_weight': 'balanced', 'max_depth': 15, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [200],\n",
    "    'max_depth': [10, 15],\n",
    "    'min_samples_split': [5, 10],\n",
    "    'min_samples_leaf': [2, 4],\n",
    "    'bootstrap': [True],\n",
    "    'class_weight': ['balanced']\n",
    "}\n",
    "\n",
    "rf_grid = GridSearchCV(\n",
    "    estimator=RandomForestClassifier(random_state=42, n_jobs=-1),\n",
    "    param_grid=rf_param_grid,\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "rf_grid.fit(X_train_processed, y_train)\n",
    "rf_best = rf_grid.best_estimator_\n",
    "print(\"RF best (City):\", rf_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4b2cedd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF Treino (City):\n",
      "  OA: 0.865\n",
      "  P_1: 0.880\n",
      "  R_1: 0.784\n",
      "  F1_1: 0.829\n",
      "  P_0: 0.857\n",
      "  R_0: 0.924\n",
      "  F1_0: 0.889\n",
      "\n",
      "RF Teste (City):\n",
      "  OA: 0.858\n",
      "  P_1: 0.878\n",
      "  R_1: 0.766\n",
      "  F1_1: 0.818\n",
      "  P_0: 0.846\n",
      "  R_0: 0.924\n",
      "  F1_0: 0.883\n"
     ]
    }
   ],
   "source": [
    "y_rf_train = rf_best.predict(X_train_processed)\n",
    "y_rf_test = rf_best.predict(X_test_processed)\n",
    "\n",
    "m_train_rf = metrics_paper(y_train, y_rf_train)\n",
    "m_test_rf = metrics_paper(y_test, y_rf_test)\n",
    "\n",
    "print(\"RF Treino (City):\")\n",
    "for k, v in m_train_rf.items():\n",
    "    print(f\"  {k}: {v:.3f}\")\n",
    "\n",
    "print(\"\\nRF Teste (City):\")\n",
    "for k, v in m_test_rf.items():\n",
    "    print(f\"  {k}: {v:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7bd4f07b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_processed: (59497, 225)\n",
      "X_test_processed : (19833, 225)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marce\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:246: UserWarning: Found unknown categories in columns [3] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "continuous_cols = X_train_fixed.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_cols = X_train_fixed.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', MinMaxScaler(), continuous_cols),\n",
    "        ('cat', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore'), categorical_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "X_train_processed = preprocessor.fit_transform(X_train_fixed)\n",
    "X_test_processed = preprocessor.transform(X_test_fixed)\n",
    "\n",
    "print(\"X_train_processed:\", X_train_processed.shape)\n",
    "print(\"X_test_processed :\", X_test_processed.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "848a0ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - OA teste: 0.858\n"
     ]
    }
   ],
   "source": [
    "print(f\"Random Forest - OA teste: {m_test['OA']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d5b013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 32 candidates, totalling 96 fits\n",
      "XGB best: {'colsample_bytree': 1.0, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 500, 'subsample': 0.8}\n"
     ]
    }
   ],
   "source": [
    "xgb_param_grid = {\n",
    "    'n_estimators': [300, 500],\n",
    "    'max_depth': [3, 6],\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "xgb_grid = GridSearchCV(\n",
    "    estimator=XGBClassifier(\n",
    "        eval_metric='logloss',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    param_grid=xgb_param_grid,\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "xgb_grid.fit(X_train_processed, y_train)\n",
    "xgb_best = xgb_grid.best_estimator_\n",
    "print(\"XGB best:\", xgb_grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9baa00b",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2a52153c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB Treino (City):\n",
      "  OA: 0.911\n",
      "  P_1: 0.909\n",
      "  R_1: 0.873\n",
      "  F1_1: 0.891\n",
      "  P_0: 0.911\n",
      "  R_0: 0.938\n",
      "  F1_0: 0.924\n",
      "\n",
      "XGB Teste (City):\n",
      "  OA: 0.882\n",
      "  P_1: 0.881\n",
      "  R_1: 0.828\n",
      "  F1_1: 0.854\n",
      "  P_0: 0.882\n",
      "  R_0: 0.920\n",
      "  F1_0: 0.900\n"
     ]
    }
   ],
   "source": [
    "y_xgb_train = xgb_best.predict(X_train_processed)\n",
    "y_xgb_test = xgb_best.predict(X_test_processed)\n",
    "\n",
    "m_train_xgb = metrics_paper(y_train, y_xgb_train)\n",
    "m_test_xgb = metrics_paper(y_test, y_xgb_test)\n",
    "\n",
    "print(\"XGB Treino (City):\")\n",
    "for k, v in m_train_xgb.items():\n",
    "    print(f\"  {k}: {v:.3f}\")\n",
    "\n",
    "print(\"\\nXGB Teste (City):\")\n",
    "for k, v in m_test_xgb.items():\n",
    "    print(f\"  {k}: {v:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "16d78f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost - OA teste: 0.882\n"
     ]
    }
   ],
   "source": [
    "print(f\"XGBoost - OA teste: {m_test_xgb['OA']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c9fff9",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3e0028b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs em X_train_svm: 0\n",
      "NaNs em X_test_svm : 0\n"
     ]
    }
   ],
   "source": [
    "imputer = SimpleImputer(strategy='median')\n",
    "\n",
    "X_train_svm = imputer.fit_transform(X_train_processed)\n",
    "X_test_svm = imputer.transform(X_test_processed)\n",
    "\n",
    "print(\"NaNs em X_train_svm:\", np.isnan(X_train_svm).sum())\n",
    "print(\"NaNs em X_test_svm :\", np.isnan(X_test_svm).sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1c81d4fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "SVM best (City): {'C': 5, 'gamma': 'scale', 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "svm_param_grid = {\n",
    "    'C': [1, 5],\n",
    "    'gamma': ['scale', 0.1, 0.01],\n",
    "    'kernel': ['rbf']\n",
    "}\n",
    "\n",
    "svm_grid = GridSearchCV(\n",
    "    estimator=SVC(random_state=42),\n",
    "    param_grid=svm_param_grid,\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "svm_grid.fit(X_train_svm, y_train)\n",
    "svm_best = svm_grid.best_estimator_\n",
    "print(\"SVM best (City):\", svm_grid.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1b55d66f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Treino:\n",
      "  OA: 0.869\n",
      "  P_1: 0.879\n",
      "  R_1: 0.794\n",
      "  F1_1: 0.834\n",
      "  P_0: 0.862\n",
      "  R_0: 0.922\n",
      "  F1_0: 0.891\n",
      "\n",
      "SVM Teste:\n",
      "  OA: 0.849\n",
      "  P_1: 0.859\n",
      "  R_1: 0.763\n",
      "  F1_1: 0.808\n",
      "  P_0: 0.843\n",
      "  R_0: 0.910\n",
      "  F1_0: 0.875\n"
     ]
    }
   ],
   "source": [
    "y_svm_train = svm_best.predict(X_train_svm)\n",
    "y_svm_test = svm_best.predict(X_test_svm)\n",
    "\n",
    "m_train_svm = metrics_paper(y_train, y_svm_train)\n",
    "m_test_svm = metrics_paper(y_test, y_svm_test)\n",
    "\n",
    "print(\"SVM Treino:\")\n",
    "for k, v in m_train_svm.items():\n",
    "    print(f\"  {k}: {v:.3f}\")\n",
    "\n",
    "print(\"\\nSVM Teste:\")\n",
    "for k, v in m_test_svm.items():\n",
    "    print(f\"  {k}: {v:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457c4250",
   "metadata": {},
   "source": [
    "### Configura√ß√£o MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "35211a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/01 13:37:35 INFO mlflow.tracking.fluent: Experiment with name 'hotel_booking_cancellation_paper_baseline' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ MLflow configurado!\n",
      "üìÅ Pasta de tracking: ./mlruns\n",
      "üî¨ Experimento: hotel_booking_cancellation_paper_baseline\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Carrega vari√°veis do .env (se tiver)\n",
    "load_dotenv()\n",
    "\n",
    "# Configura tracking local (cria pasta ./mlruns na raiz do projeto)\n",
    "mlflow.set_tracking_uri(\"file:../mlruns\")\n",
    "\n",
    "# Cria/seleciona experimento\n",
    "mlflow.set_experiment(\"hotel_booking_cancellation_paper_baseline\")\n",
    "\n",
    "print(\"‚úÖ MLflow configurado!\")\n",
    "print(\"üìÅ Pasta de tracking: ./mlruns\")\n",
    "print(\"üî¨ Experimento: hotel_booking_cancellation_paper_baseline\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9109598e",
   "metadata": {},
   "source": [
    "### Ensemble Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "92bbc7cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Treino:\n",
      "  OA: 0.888\n",
      "  P_1: 0.915\n",
      "  R_1: 0.805\n",
      "  F1_1: 0.857\n",
      "  P_0: 0.872\n",
      "  R_0: 0.947\n",
      "  F1_0: 0.908\n",
      "\n",
      "Ensemble Teste:\n",
      "  OA: 0.870\n",
      "  P_1: 0.902\n",
      "  R_1: 0.772\n",
      "  F1_1: 0.832\n",
      "  P_0: 0.852\n",
      "  R_0: 0.940\n",
      "  F1_0: 0.894\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_train_svm = imputer.fit_transform(X_train_processed)\n",
    "X_test_svm = imputer.transform(X_test_processed)\n",
    "\n",
    "ensemble = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', rf_best),\n",
    "        ('svm', svm_best),\n",
    "        ('xgb', xgb_best),\n",
    "        ('mlp', mlp_best)\n",
    "    ],\n",
    "    voting='hard'\n",
    ")\n",
    "\n",
    "# usar os dados imputados, sem NaN\n",
    "ensemble.fit(X_train_svm, y_train)\n",
    "\n",
    "y_ens_train = ensemble.predict(X_train_svm)\n",
    "y_ens_test = ensemble.predict(X_test_svm)\n",
    "\n",
    "m_train_ens = metrics_paper(y_train, y_ens_train)\n",
    "m_test_ens = metrics_paper(y_test, y_ens_test)\n",
    "\n",
    "print(\"Ensemble Treino:\")\n",
    "for k, v in m_train_ens.items():\n",
    "    print(f\"  {k}: {v:.3f}\")\n",
    "\n",
    "print(\"\\nEnsemble Teste:\")\n",
    "for k, v in m_test_ens.items():\n",
    "    print(f\"  {k}: {v:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e22c4acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF   - OA teste: 0.858\n",
      "SVM  - OA teste: 0.849\n",
      "XGB  - OA teste: 0.882\n",
      "MLP  - OA teste: 0.855\n",
      "ENS  - OA teste: 0.870\n"
     ]
    }
   ],
   "source": [
    "print(f\"RF   - OA teste: {m_test_rf['OA']:.3f}\")\n",
    "print(f\"SVM  - OA teste: {m_test_svm['OA']:.3f}\")\n",
    "print(f\"XGB  - OA teste: {m_test_xgb['OA']:.3f}\")\n",
    "print(f\"MLP  - OA teste: {m_test_mlp['OA']:.3f}\")\n",
    "print(f\"ENS  - OA teste: {m_test_ens['OA']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e7f078",
   "metadata": {},
   "source": [
    "### Contribui√ß√£o para o paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e0e4e180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs em X_train_mlp: 0\n",
      "NaNs em X_test_mlp : 0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "\n",
    "X_train_mlp = imputer.fit_transform(X_train_processed)\n",
    "X_test_mlp = imputer.transform(X_test_processed)\n",
    "\n",
    "print(\"NaNs em X_train_mlp:\", np.isnan(X_train_mlp).sum())\n",
    "print(\"NaNs em X_test_mlp :\", np.isnan(X_test_mlp).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4b9f24e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "MLP best: {'activation': 'relu', 'alpha': 0.0001, 'batch_size': 256, 'hidden_layer_sizes': (64,), 'learning_rate_init': 0.001, 'max_iter': 100, 'solver': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "mlp_param_grid = {\n",
    "    'hidden_layer_sizes': [(64,), (64, 32)],\n",
    "    'activation': ['relu'],\n",
    "    'solver': ['adam'],\n",
    "    'alpha': [1e-4, 1e-3],\n",
    "    'learning_rate_init': [0.001],\n",
    "    'max_iter': [100],\n",
    "    'batch_size': [256]\n",
    "}\n",
    "\n",
    "mlp_grid = GridSearchCV(\n",
    "    estimator=MLPClassifier(random_state=42),\n",
    "    param_grid=mlp_param_grid,\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# CORRE√á√ÉO: usar X_train_mlp, n√£o X_train_processed\n",
    "mlp_grid.fit(X_train_mlp, y_train)\n",
    "mlp_best = mlp_grid.best_estimator_\n",
    "print(\"MLP best:\", mlp_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8a214f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Treino:\n",
      "  OA: 0.879\n",
      "  P_1: 0.869\n",
      "  R_1: 0.835\n",
      "  F1_1: 0.852\n",
      "  P_0: 0.885\n",
      "  R_0: 0.910\n",
      "  F1_0: 0.897\n",
      "\n",
      "MLP Teste:\n",
      "  OA: 0.855\n",
      "  P_1: 0.844\n",
      "  R_1: 0.802\n",
      "  F1_1: 0.822\n",
      "  P_0: 0.863\n",
      "  R_0: 0.894\n",
      "  F1_0: 0.878\n"
     ]
    }
   ],
   "source": [
    "y_mlp_train = mlp_best.predict(X_train_mlp)\n",
    "y_mlp_test = mlp_best.predict(X_test_mlp)\n",
    "\n",
    "m_train_mlp = metrics_paper(y_train, y_mlp_train)\n",
    "m_test_mlp = metrics_paper(y_test, y_mlp_test)\n",
    "\n",
    "print(\"MLP Treino:\")\n",
    "for k, v in m_train_mlp.items():\n",
    "    print(f\"  {k}: {v:.3f}\")\n",
    "\n",
    "print(\"\\nMLP Teste:\")\n",
    "for k, v in m_test_mlp.items():\n",
    "    print(f\"  {k}: {v:.3f}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
